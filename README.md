# AION-Search: Semantic search for galaxy images using AI-generated captions

[![arXiv](https://img.shields.io/badge/arXiv-Coming%20Soon-b31b1b.svg)](https://arxiv.org)
[![Project Page](https://img.shields.io/badge/Project-Page-green.svg)](https://aion-search.github.io)
[![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97%20Dataset-HuggingFace-yellow.svg)](https://huggingface.co/collections/astronolan/aion-search)
[![Demo](https://img.shields.io/badge/%F0%9F%9A%80%20Demo-HuggingFace-blue.svg)](https://astronolan-aion-search.hf.space/)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Citation](https://img.shields.io/badge/Citation-BibTeX-orange.svg)](#citation)

AION-Search is a text-based search engine for galaxy images that was trained on 300k captions generated by GPT-4.1-mini. It can be used to find rare phenomena with natural language search!

üî≠ **Use AION-Search now!**  
Try the live web demo: [AION-Search App](https://astronolan-aion-search.hf.space/)

üìö **Checkout our results**  
More details at: [Project Page](https://aion-search.github.io/)

üì¶ **Explore Our Datasets**  
Access all data products (embeddings and captions): [HuggingFace Datasets](https://huggingface.co/collections/astronolan/aion-search)

## Quick Start

### Installation

```bash
git clone https://github.com/astronolan/aion-search.git
cd aion-search
pip install -e . # or uv pip install -e .
```

### Requirements

This package requires an **OpenAI API key** for generating text embeddings.

1. Get your API key at [platform.openai.com](https://platform.openai.com)
2. Create a `.env` file in the project root:
   ```bash
   OPENAI_API_KEY=sk-your-key-here
   ```

### Usage

```python
from aionsearch import AIONSearchClipModel

# Load pretrained model from HuggingFace
model = AIONSearchClipModel.from_pretrained()

# Project AION image embeddings into shared space
aion_embedding = # Embedding of an image using github.com/PolymathicAI/AION
projected_image = model.image_projector(aion_embedding)  # (batch, 768) -> (batch, 1024)

# Project OpenAI text embeddings into shared space  
text_embedding = # Embedding of text using text-embedding-3-large
projected_text = model.text_projector(text_embedding)    # (batch, 3072) -> (batch, 1024)

# Compute similarity for semantic search
similarity = projected_image @ projected_text.T
```

See [`examples/quick_start.ipynb`](examples/quick_start.ipynb) for a complete walkthrough that downloads a galaxy image, generates embeddings with AION, and performs text-to-image similarity search.

---

## Research Code

> ‚ö†Ô∏è **The code in `research/` is provided for reference only.** It is the code used for the paper methodology but currently requires internal infrastructure.

---

## Citation

If you find this work useful, please cite:

```bibtex
@misc{koblischke2025semantic,
      title={Semantic search for 100M+ galaxy images using AI-generated captions}, 
      author={Nolan Koblischke and Liam Parker and Francois Lanusse and Irina Espejo Morales and Jo Bovy and Shirley Ho},
      year={2025},
      eprint={2512.11982},
      archivePrefix={arXiv},
      primaryClass={astro-ph.IM},
      url={https://arxiv.org/abs/2512.11982}, 
}
```
