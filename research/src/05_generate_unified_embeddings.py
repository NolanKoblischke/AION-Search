#!/usr/bin/env python3
"""
Generate AION embeddings and create unified parquet files.
This script combines AION embedding generation with parquet creation in one step.
Handles text embeddings with potential augmented descriptions.

Requires:
- galaxy_data.hdf5 from 01_collect_galaxies.py
- galaxy_text_embeddings.hdf5 from 04_generate_text_embeddings.py (updated version)
"""

import h5py
import numpy as np
import pandas as pd
import torch
from pathlib import Path
import time
from datetime import datetime
import logging
from logging.handlers import RotatingFileHandler
from tqdm import tqdm
import argparse
import json
import pyarrow as pa
import pyarrow.parquet as pq
from collections import defaultdict
from dotenv import load_dotenv

# AION imports
from aion.modalities import LegacySurveyImage, HSCImage
from aion.codecs import CodecManager
from aion.model import AION

# Load environment variables from .env file
load_dotenv()

# Configuration
BATCH_SIZE = 256  # Process galaxies in batches
MB = 1024 * 1024

# Set up logging
logger = logging.getLogger(__name__)


def setup_logging(log_file):
    """Configure logging to both file and console."""
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    
    # File handler with rotation (10MB max, keep 5 backups)
    file_handler = RotatingFileHandler(
        log_file, maxBytes=10*1024*1024, backupCount=5
    )
    file_handler.setFormatter(formatter)
    file_handler.setLevel(logging.INFO)
    
    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    console_handler.setLevel(logging.INFO)
    
    # Configure root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)


def process_hsc_batch(images, model, codec_manager, device):
    """Process a batch of HSC images and return embeddings."""
    # Convert to torch tensor
    image_flux = torch.tensor(images.astype('float32')).to(device)
    
    # Create typed image
    typed_image = HSCImage(
        flux=image_flux,
        bands=["HSC-G", "HSC-R", "HSC-I", "HSC-Z", "HSC-Y"]
    )
    
    # Encode to tokens
    tokens = codec_manager.encode(typed_image)
    
    # Get embeddings - requesting 576 tokens (standard AION output)
    with torch.no_grad():
        embeddings = model.encode(tokens, num_encoder_tokens=576)
    
    # AION returns shape (batch, tokens, dim) = (batch, 576, 768)
    # We want (batch, dim, tokens) = (batch, 768, 576)
    embeddings = embeddings.transpose(1, 2)
    
    return embeddings.detach().cpu().numpy()


def process_legacy_batch(images, model, codec_manager, device):
    """Process a batch of Legacy images and return embeddings."""
    # Remove NaN padding from 5th channel
    images = images[:, :4, :, :]
    
    # Convert to torch tensor
    image_flux = torch.tensor(images.astype('float32')).to(device)
    
    # Create typed image
    typed_image = LegacySurveyImage(
        flux=image_flux,
        bands=["DES-G", "DES-R", "DES-I", "DES-Z"]
    )
    
    # Encode to tokens
    tokens = codec_manager.encode(typed_image)
    
    # Get embeddings
    with torch.no_grad():
        embeddings = model.encode(tokens, num_encoder_tokens=600)
    
    # AION returns shape (batch, tokens, dim) = (batch, 576, 768)
    # We want (batch, dim, tokens) = (batch, 768, 576)
    embeddings = embeddings.transpose(1, 2)
    
    return embeddings.detach().cpu().numpy()




def create_unified_parquet(
    galaxy_data_path: Path,
    text_embeddings_path: Path,
    output_path: Path,
    model: AION = None,
    codec_manager = None,
    device: str = "cuda",
    batch_size: int = BATCH_SIZE,
    use_mean_aion: bool = True,
):
    """Create a unified parquet file with all embeddings."""
    logger.info("Creating unified parquet file")
    
    # Load text embeddings metadata to understand structure
    logger.info(f"Loading text embeddings from {text_embeddings_path}")
    with h5py.File(text_embeddings_path, 'r') as f:
        # All files from step 4 now have the new structure
        if 'embeddings_by_galaxy' not in f.attrs:
            raise ValueError("Text embeddings file must be generated by the updated step 04 script")
        
        logger.info("Loading embedding structure with potential augmented data")
        
        # Read the structured data
        text_embeddings = f['text_embedding'][:]
        descriptions = f['description'][:]
        object_ids = f['object_id'][:]
        
        if 'galaxy_data_index' not in f:
            raise ValueError("Text embeddings file missing galaxy_data_index - this is required for proper alignment")
        galaxy_data_indices = f['galaxy_data_index'][:]
        logger.info(f"Loaded galaxy_data_index mapping with {len(galaxy_data_indices)} entries")
        
        # Load augmented descriptions if available
        augmented_descriptions_by_idx = {}
        if 'augmented_descriptions' in f:
            logger.info("Loading augmented descriptions...")
            augmented_desc_data = f['augmented_descriptions'][:]
            for i, aug_json in enumerate(augmented_desc_data):
                if isinstance(aug_json, bytes):
                    aug_json = aug_json.decode('utf-8')
                try:
                    aug_list = json.loads(aug_json)
                    if aug_list:  # Only store non-empty lists
                        augmented_descriptions_by_idx[i] = aug_list
                except json.JSONDecodeError:
                    logger.warning(f"Failed to parse augmented descriptions for index {i}")
            logger.info(f"Loaded augmented descriptions for {len(augmented_descriptions_by_idx)} galaxies")
        else:
            logger.info("No augmented descriptions found in text embeddings file")
        
        # Decode strings
        descriptions = [desc.decode('utf-8') if isinstance(desc, bytes) else desc for desc in descriptions]
        object_ids = [oid.decode('utf-8') if isinstance(oid, bytes) else oid for oid in object_ids]
        
        # Build embeddings_by_galaxy structure from the flat arrays
        embeddings_by_galaxy = {}
        text_metadata = []
        
        # Read metadata
        if 'text_metadata' in f:
            text_metadata = json.loads(f['text_metadata'][()].decode('utf-8'))
        else:
            raise ValueError("Text embeddings file missing text_metadata - please regenerate with updated step 04")
        
        # Reconstruct the structure with correct galaxy_data indices
        for i, metadata in enumerate(text_metadata):
            galaxy_idx = metadata['galaxy_idx']  # This is just the sequential index in the text file
            actual_galaxy_data_idx = int(galaxy_data_indices[galaxy_idx])  # This is the correct index for galaxy_data.hdf5
            
            if actual_galaxy_data_idx not in embeddings_by_galaxy:
                embeddings_by_galaxy[actual_galaxy_data_idx] = {
                    'object_id': metadata['object_id'],
                    'embeddings': [],
                    'descriptions': [],
                    'text_types': [],
                    'text_file_idx': galaxy_idx  # Keep original index for reference
                }
            embeddings_by_galaxy[actual_galaxy_data_idx]['embeddings'].append(text_embeddings[i])
            embeddings_by_galaxy[actual_galaxy_data_idx]['text_types'].append(metadata['text_type'])
            
            # Get the appropriate description
            if metadata['text_type'] == 'original':
                embeddings_by_galaxy[actual_galaxy_data_idx]['descriptions'].append(descriptions[galaxy_idx])
            else:
                # For augmented, get from augmented_descriptions_by_idx
                text_idx = metadata.get('text_idx', 0) - 1  # text_idx starts at 1 for augmented
                if galaxy_idx in augmented_descriptions_by_idx and text_idx < len(augmented_descriptions_by_idx[galaxy_idx]):
                    aug_desc = augmented_descriptions_by_idx[galaxy_idx][text_idx]
                    embeddings_by_galaxy[actual_galaxy_data_idx]['descriptions'].append(aug_desc)
                else:
                    logger.debug(f"Augmented description for galaxy {galaxy_idx} text_idx {text_idx} not found, using empty string")
                    embeddings_by_galaxy[actual_galaxy_data_idx]['descriptions'].append('')
    
    # Get valid galaxy indices (these are now the correct indices for galaxy_data.hdf5)
    valid_galaxy_indices = sorted(embeddings_by_galaxy.keys())
    
    logger.info(f"Valid galaxies: {len(valid_galaxy_indices):,}")
    logger.info(f"Galaxy index range: {min(valid_galaxy_indices)} to {max(valid_galaxy_indices)}")
    
    # Open galaxy data
    logger.info(f"Loading galaxy data from {galaxy_data_path}")
    
    data_records = []
    object_id_mismatches = 0
    
    with h5py.File(galaxy_data_path, 'r') as f_galaxy:
        # Process in batches
        for batch_start in tqdm(range(0, len(valid_galaxy_indices), batch_size), 
                               desc="Processing galaxies"):
            batch_end = min(batch_start + batch_size, len(valid_galaxy_indices))
            
            # Get indices for this batch
            batch_galaxy_idx = valid_galaxy_indices[batch_start:batch_end]
            
            # Load galaxy data
            images = f_galaxy['image_array'][batch_galaxy_idx]
            groups = f_galaxy['group'][batch_galaxy_idx]
            galaxy_object_ids = f_galaxy['object_id'][batch_galaxy_idx]
            
            # Decode strings
            groups = [g.decode() if isinstance(g, bytes) else g for g in groups]
            galaxy_object_ids = [oid.decode() if isinstance(oid, bytes) else oid for oid in galaxy_object_ids]
            
            # Generate AION embeddings if model provided
            if model is not None:
                # Process by survey type
                hsc_mask = np.array([g == 'HSC' for g in groups])
                legacy_mask = np.array([g == 'Legacy' for g in groups])
                
                aion_embeddings = np.zeros((len(images), 768, 576), dtype=np.float32)
                
                if hsc_mask.any():
                    hsc_embeddings = process_hsc_batch(images[hsc_mask], model, codec_manager, device)
                    aion_embeddings[hsc_mask] = hsc_embeddings
                
                if legacy_mask.any():
                    legacy_embeddings = process_legacy_batch(images[legacy_mask], model, codec_manager, device)
                    aion_embeddings[legacy_mask] = legacy_embeddings
                
                # Apply mean if requested
                if use_mean_aion:
                    aion_embeddings = aion_embeddings.mean(axis=2)  # Mean over tokens
            else:
                # Create placeholder
                aion_dim = 768 if use_mean_aion else 768 * 576
                aion_embeddings = np.zeros((len(images), aion_dim), dtype=np.float32)
            
            # Create records
            for i in range(len(batch_galaxy_idx)):
                galaxy_idx = int(batch_galaxy_idx[i])
                
                # Get text embedding data for this galaxy
                if galaxy_idx in embeddings_by_galaxy:
                    emb_data = embeddings_by_galaxy[galaxy_idx]
                    
                    # Get the original embedding and description
                    original_idx = next((j for j, t in enumerate(emb_data['text_types']) if t == 'original'), 0)
                    original_embedding = emb_data['embeddings'][original_idx]
                    original_description = emb_data['descriptions'][original_idx]
                    
                    # Get augmented embeddings and descriptions if any
                    augmented_embeddings = []
                    augmented_descriptions = []
                    for j, t in enumerate(emb_data['text_types']):
                        if t == 'augmented':
                            augmented_embeddings.append(emb_data['embeddings'][j])
                            # Get the corresponding description
                            if j < len(emb_data['descriptions']):
                                augmented_descriptions.append(emb_data['descriptions'][j])
                            else:
                                augmented_descriptions.append('')  # Fallback
                    
                    # Verify object IDs match
                    if galaxy_object_ids[i] != emb_data['object_id']:
                        object_id_mismatches += 1
                        if object_id_mismatches <= 5:  # Only log first few
                            logger.warning(f"Object ID mismatch! Galaxy data: {galaxy_object_ids[i]}, Text data: {emb_data['object_id']}")
                    
                    record = {
                        'object_id': galaxy_object_ids[i],  # Use the object_id from galaxy_data.hdf5
                        'galaxy_index': galaxy_idx,
                        'aion_embedding': aion_embeddings[i].tolist() if use_mean_aion else aion_embeddings[i].flatten().tolist(),
                        'text_embedding': original_embedding.tolist(),
                        'original_description': original_description,
                        'augmented_embeddings': [emb.tolist() for emb in augmented_embeddings],
                        'augmented_descriptions': augmented_descriptions,
                        'description_sources': ['original'] + [f'gpt-4.1-nano-summary-{j+1}' for j in range(len(augmented_embeddings))]
                    }
                else:
                    # This shouldn't happen, but handle gracefully
                    logger.warning(f"No text embedding found for galaxy {galaxy_idx}")
                    continue
                
                data_records.append(record)
    
    # Create DataFrame
    df = pd.DataFrame(data_records)
    
    # Add metadata columns
    df['embedding_model'] = 'text-embedding-3-large'  # From step 4
    df['aion_model'] = 'polymathic-ai/aion-base'
    df['generation_timestamp'] = datetime.now().isoformat()
    df['use_mean_aion'] = use_mean_aion
    
    # Save to parquet
    logger.info(f"Saving to {output_path}")
    df.to_parquet(output_path, engine='pyarrow', compression='snappy')
    
    # Log statistics
    total_augmented = sum(1 for _, row in df.iterrows() if len(row['augmented_embeddings']) > 0)
    if total_augmented > 0:
        avg_summaries = df[df['augmented_embeddings'].apply(len) > 0]['augmented_embeddings'].apply(len).mean()
    else:
        avg_summaries = 0
    
    logger.info(f"Created parquet file with:")
    logger.info(f"  - {len(df)} total galaxies")
    logger.info(f"  - {total_augmented} galaxies with augmented embeddings")
    logger.info(f"  - {avg_summaries:.1f} average augmented embeddings per galaxy")
    logger.info(f"  - AION embeddings: {'mean' if use_mean_aion else 'full'} ({768 if use_mean_aion else 768*576} dims)")
    logger.info(f"  - Text embeddings: {len(df.iloc[0]['text_embedding']) if len(df) > 0 else 'N/A'} dims")
    logger.info(f"  - File size: {output_path.stat().st_size / 1024 / 1024:.1f} MB")
    
    if object_id_mismatches > 0:
        logger.warning(f"ALERT: Found {object_id_mismatches} object ID mismatches between galaxy_data and text embeddings!")
    else:
        logger.info("âœ“ All object IDs matched correctly between files")


def main():
    """Main function to generate AION embeddings and create unified parquet."""
    parser = argparse.ArgumentParser(description='Generate AION embeddings and create unified parquet')
    parser.add_argument('--galaxy-data', type=str, default='data/processed/galaxy_data.hdf5',
                       help='Input HDF5 file with galaxy data')
    parser.add_argument('--text-embeddings', type=str, 
                       default='data/processed/galaxy_text_embeddings.hdf5',
                       help='Text embeddings HDF5 file')
    parser.add_argument('--output', type=str, default='data/processed/galaxy_embeddings_unified.parquet',
                       help='Output parquet file path')
    parser.add_argument('--batch-size', type=int, default=BATCH_SIZE,
                       help='Batch size for processing')
    parser.add_argument('--device', type=str, default='cuda',
                       help='Device to use (cuda or cpu)')
    parser.add_argument('--model', type=str, default='polymathic-ai/aion-base',
                       help='AION model to use')
    parser.add_argument('--use-mean-aion', action='store_true', default=True,
                       help='Use mean of AION embeddings instead of full')
    parser.add_argument('--skip-aion', action='store_true',
                       help='Skip AION embedding generation (for testing)')
    
    args = parser.parse_args()
    
    start_time = time.time()
    
    # Create output directories
    output_path = Path(args.output)
    output_path.parent.mkdir(exist_ok=True, parents=True)
    Path("data/logs").mkdir(exist_ok=True, parents=True)
    
    # Set up logging
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = Path("data/logs") / f"aion_embeddings_unified_{timestamp}.log"
    setup_logging(log_file)
    
    logger.info("="*60)
    logger.info("AION Embedding Generation and Unified Parquet Creation")
    logger.info("="*60)
    logger.info(f"Galaxy data: {args.galaxy_data}")
    logger.info(f"Text embeddings: {args.text_embeddings}")
    logger.info(f"Output: {args.output}")
    logger.info(f"Batch size: {args.batch_size}")
    logger.info(f"Device: {args.device}")
    logger.info(f"Model: {args.model}")
    logger.info(f"Use mean AION: {args.use_mean_aion}")
    logger.info(f"Skip AION: {args.skip_aion}")
    
    # Check if CUDA is available
    if args.device == 'cuda' and not torch.cuda.is_available():
        logger.warning("CUDA not available, falling back to CPU")
        args.device = 'cpu'
    
    # Load AION model if not skipping
    model = None
    codec_manager = None
    if not args.skip_aion:
        logger.info("Loading AION model...")
        model = AION.from_pretrained(args.model).to(args.device).eval()
        codec_manager = CodecManager(device=args.device)
        logger.info("AION model loaded successfully")
    
    # Create unified parquet
    create_unified_parquet(
        galaxy_data_path=Path(args.galaxy_data),
        text_embeddings_path=Path(args.text_embeddings),
        output_path=output_path,
        model=model,
        codec_manager=codec_manager,
        device=args.device,
        batch_size=args.batch_size,
        use_mean_aion=args.use_mean_aion
    )
    
    # Final summary
    elapsed_time = time.time() - start_time
    logger.info("\n" + "="*60)
    logger.info("Processing complete!")
    logger.info("="*60)
    logger.info(f"Total time: {elapsed_time/60:.1f} minutes")
    logger.info(f"Output file: {args.output}")
    

if __name__ == "__main__":
    main()